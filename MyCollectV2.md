# MyCollectV2

What the global idea: 

Collect from many sources links to pages that matches the user searches.
Process the pages to find the most relevant content, notify the user on a regular basis.

Flow:

* Each collector fetches data from its source, using the user searches if the source accepts it
* Collectors forward collected items to the storage
* Processor grab on a regular basis the newest content, apply ML to extract the key features
* Output reads the content generated by the processor and send info to the user

## Collector store

MyCollect should have a storage helper that will perform batch queries instead of single operation.

Item to be stored:

* text
* url
* category (if applicable)
* date

The storage also requires a process that will perform basic actions on an unseen url:

* get url content
* parse HTML
* extract structure, like title & content (if applicable)
* increment url counter and last update

### Schemas

collected_url

* url
* date
* text

url

* url
* unstructured (HTML/PDF ...)
* structured (JSON like data)